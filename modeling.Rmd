# Hierarchical Modeling

```{r, echo=FALSE}
library(tidyverse)         # for reading in data, graphing, and cleaning
library(tidymodels)        # for modeling ... tidily
library(usemodels)         # for suggesting step_XXX() functions
library(glmnet)            # for regularized regression, including LASSO
library(naniar)            # for examining missing values (NAs)
library(lubridate)         # for date  manipulation
library(moderndive)        # for King County housing data
library(vip)               # for variable importance plots
library(rmarkdown)         # for paged tables
library(dplyr)
library(janitor)
library(ggplot2)
library(ggpubr)
library(dplyr)
library(bayesforecast)    # Bayes Forecasting (Playing around) 
library(bayesrules)
library(tidyverse)
library(rstanarm)
library(broom.mixed)
library(tidybayes)
library(tidyverse)
library(bayesplot)
library(ggplot2)
```

```{r, echo=FALSE}
data <- read.csv("FINALDATASET.csv")
#Selecting necessary variables
data <- dplyr::select(data, c("YEAR", "COMPANY", "MARKET.CAP", "EARNINGS", "SALES", "CASH", "Name", "Sector", "Earnings_next_year"))

#Scaling Variables of Interest
data <- data %>% 
  mutate(EARNINGS_Scaled = EARNINGS/1000000000,
         CASH_Scaled = CASH/1000000000,
         MARKET.CAP_Scaled = MARKET.CAP/1000000000,
         Earnings_next_year_Scaled = Earnings_next_year/1000000000,
         SALES_Scaled = SALES/1000000000)

#Adding Lagged Variables
data <- data %>% 
  group_by(COMPANY) %>%
  mutate(EARNINGS_1_YEAR_AGO = lead(EARNINGS_Scaled, n = 1), 
         EARNINGS_2_YEAR_AGO = lead(EARNINGS_Scaled, n = 2),
         EARNINGS_3_YEAR_AGO = lead(EARNINGS_Scaled, n = 3),
         EARNINGS_4_YEAR_AGO = lead(EARNINGS_Scaled, n = 4)) %>% 
  mutate(SALES_1_YEAR_AGO = lead(SALES_Scaled, n = 1),
         SALES_2_YEAR_AGO = lead(SALES_Scaled, n = 2),
         SALES_3_YEAR_AGO = lead(SALES_Scaled, n = 3),
         SALES_4_YEAR_AGO = lead(SALES_Scaled, n = 4))

#Add_Dummy if Company is 100
temp <- data %>% 
  group_by(COMPANY) %>% 
  summarize(count = n(), 
            mean_MC = mean(MARKET.CAP)) %>% 
  filter(count == 23) %>% 
  arrange(desc(mean_MC)) %>% 
  head(100)

temp <- temp$COMPANY

data <- data %>% 
  mutate(Is_top_100 = case_when(COMPANY %in% temp ~ 1,TRUE ~ 0))
```


## Set Up

Since we have time-series data, we created a testing set by sub-setting each company's 2nd to latest year. We will predict earnings next year with the testing set and compare it with the actual values to help determine model accuracy.

```{r, include=FALSE}
Q <- quantile(data$Earnings_next_year_Scaled, probs=c(.25, .75), na.rm = TRUE)
iqr <- IQR(data$Earnings_next_year_Scaled, na.rm = TRUE)
up <-  Q[2]+.90*iqr # Upper Range  
low<- Q[1]-.90*iqr # Lower Range
eliminated<- subset(data, data$Earnings_next_year_Scaled > (low) & data$Earnings_next_year_Scaled < (up))
data_elimatedO <- eliminated
```

```{r}
testing <- data_elimatedO %>% 
   group_by(COMPANY) %>% 
   filter(row_number()==1)

training <- anti_join(data_elimatedO, testing)
```

```{r, include=FALSE}
#Custom Functions
predict_model<- function(Company, Model){
  test_comp <- Company
  test_1 <- testing %>% 
    filter(COMPANY == test_comp)
  predict_next_year <- posterior_predict(
  Model, 
  newdata = data.frame(test_1))
  most_recent_year <- testing %>% 
   filter(COMPANY == test_comp) %>% 
   filter(row_number()==1)
most_recent_year <- most_recent_year$YEAR
actual <- data %>% 
  filter(COMPANY == test_comp & YEAR == most_recent_year-1) %>% 
  select(c("EARNINGS_Scaled","YEAR"))
actual <- actual$EARNINGS_Scaled
randomsample <- sample_n(as.data.frame(predict_next_year), 750)
graphing_predictions <- randomsample %>% 
  mutate(EARNINGS_Scaled = `1`,
         YEAR = most_recent_year) %>% 
  add_row(EARNINGS_Scaled = actual, YEAR = most_recent_year -1) %>% 
  select(c("EARNINGS_Scaled","YEAR"))
g <- data %>% 
  filter(COMPANY == test_comp) %>% 
  filter(YEAR <= most_recent_year) %>% 
  ggplot(aes(x= YEAR, y=EARNINGS_Scaled))+
  geom_point() +
  geom_line() +
  geom_segment(data = graphing_predictions, aes(x = most_recent_year - 1, 
                   xend = most_recent_year,
                   y = actual, 
                   yend = EARNINGS_Scaled),
               alpha = 0.03,
               colour = "red")
  return(g)
}

collect_metrics_pred <- function(Model, Datametric){
  predictions_mode_2 <- posterior_predict(
  Model, 
  newdata = data.frame(Datametric))
prediction_dataframe <- as.data.frame(predictions_mode_2)

temp <- prediction_dataframe %>% 
bind_rows(summarise(.,across(where(is.numeric),median),
                    across(where(is.character),~"Median")))
meadian_predictions <- tail(temp, 1)
meadian_predictions <- t(meadian_predictions)
meadian_predictions<-as.data.frame(meadian_predictions)
meadian_predictions <- meadian_predictions %>% 
  mutate(median = `20001`) %>% 
  select(median)

temp <- prediction_dataframe %>% 
bind_rows(summarise(.,across(where(is.numeric),quantile, .025),
                    across(where(is.character),~"Lower95")))
predictions_lower <- tail(temp, 1)
predictions_lower <- t(predictions_lower)
predictions_lower<-as.data.frame(predictions_lower)
predictions_lower95 <- predictions_lower %>% 
  mutate(lower95 = `20001`) %>% 
  select(lower95)

temp <- prediction_dataframe %>% 
bind_rows(summarise(.,across(where(is.numeric),quantile, .25),
                    across(where(is.character),~"Lower50")))
predictions_lower <- tail(temp, 1)
predictions_lower <- t(predictions_lower)
predictions_lower<-as.data.frame(predictions_lower)
predictions_lower50 <- predictions_lower %>% 
  mutate(lower50 = `20001`) %>% 
  select(lower50)

temp <- prediction_dataframe %>% 
bind_rows(summarise(.,across(where(is.numeric),quantile, .975),
                    across(where(is.character),~"Upper95")))
predictions_upper <- tail(temp, 1)
predictions_upper <- t(predictions_upper)
predictions_upper<-as.data.frame(predictions_upper)
predictions_upper95 <- predictions_upper %>% 
  mutate(upper95 = `20001`) %>% 
  select(upper95)

temp <- prediction_dataframe %>% 
bind_rows(summarise(.,across(where(is.numeric),quantile, .75),
                    across(where(is.character),~"Upper50")))
predictions_upper <- tail(temp, 1)
predictions_upper <- t(predictions_upper)
predictions_upper<-as.data.frame(predictions_upper)
predictions_upper50 <- predictions_upper %>% 
  mutate(upper50 = `20001`) %>% 
  select(upper50)

Testing_with_metrics <- cbind(Datametric, predictions_upper95, predictions_lower95,predictions_upper50,predictions_lower50, meadian_predictions)

median_error <- Testing_with_metrics %>% 
  mutate(absDist = abs(median - Earnings_next_year_Scaled))

in_95 <- Testing_with_metrics %>% 
  mutate(Is_95 = (Earnings_next_year_Scaled < upper95) & (Earnings_next_year_Scaled > lower95))

in_50 <- Testing_with_metrics %>% 
  mutate(Is_50 = (Earnings_next_year_Scaled < upper50) & (Earnings_next_year_Scaled > lower50))

med <- median(median_error$absDist)
mean95 <- mean(in_95$Is_95)
mean50 <- mean(in_50$Is_50)
model_2_metrics <- matrix(c(med,mean95,mean50), ncol = 3)
colnames(model_2_metrics) <- c("MAE","Within95","Within50")
model_2_metrics <- as.data.frame(model_2_metrics)
return(model_2_metrics)
}
```



## Model 1: Hierarchical w/ Different Intercepts

### Model Structure

Now, we will move on to utilizing the structure of our data, where we have consecutive observations for each company for several years. We start with a model with varying intercepts. Note: we fit each model using training data for evaluation purposes.

```{r}
Diff_inter_train <- readRDS("Diff_inter_train_nick.rds")
```

```{r, eval=FALSE}
model_diff_inter_train_data <- training %>% 
  select(c("Earnings_next_year_Scaled","EARNINGS_Scaled","EARNINGS_1_YEAR_AGO","COMPANY","Sector")) %>% na.omit()

model_diff_inter_train <- stan_glmer(
  Earnings_next_year_Scaled ~ EARNINGS_Scaled + EARNINGS_1_YEAR_AGO  + Sector + (1 | COMPANY) , data = model_diff_inter_train_data, 
  family = gaussian,
  chains = 4, iter = 5000*2, seed = 84735, 
  prior_PD = FALSE, refresh = 0)

write_rds(model_diff_inter_train, "Diff_Inter_train_nick.rds")
```

```{r, eval=FALSE}
prior_summary(Diff_inter_train)
```

Below is the notation for the differing intercepts model:

$$\begin{split}
\text{Relationship within company:} & \\
Y_{ij} | \beta_{0j}, \beta_1, \sigma_y 
& \sim N(\mu_{ij}, \sigma_y^2) \;\; \text{ where } \mu_{ij} = \beta_{0j} + \beta_1 X_{ij} + \beta_2 X_{ij} + \beta_3 X_{ij}...\\
& \\
\text{Variability between companies:} & \\
\beta_{0j} & \stackrel{ind}{\sim} N(\beta_0, \sigma_0^2) \\
& \\
\text{Prior information on Globals with Adjusted Prior} & \\
\beta_{0c} & \sim N(0.59, 1.5^2) \\
\beta_1 & \sim N(0, 1.74^2) \\
\beta_2 & \sim N(0, 1.60^2) \\
\beta_3 & \sim N(0, 4.60^2) \\
.\\
.\\
.\\
\sigma_y  & \sim \text{Exp}(1.6) \\
\sigma_0  & \sim \text{Exp}(1) \\
\end{split}$$



## Model 2: Hierarchical w/ Different Slopes and Intercepts

### Model Structure

In addition to having a hierarchical regression with different intercepts, we decided to add a model with different intercepts and slopes.  

**Rational behind different slopes:**

Below we graph 4 random companies, we can see that earnings in the current year impacts earnings next year differently among different companies. 

```{r}
eliminated %>% 
  filter(COMPANY %in% c("AAL","CVS","DAL","WAB")) %>% 
  ggplot(., aes(x = EARNINGS_Scaled, y = Earnings_next_year_Scaled)) + 
    geom_point() + 
    geom_smooth(method = "lm", se = FALSE) + 
    facet_grid(~ COMPANY)
```

To get a better idea of the varying slopes, I graph 50 random companies together. 

```{r}
vector <- eliminated$COMPANY
vector <- sample_n(as.data.frame(vector), 50)
vector <- as.list(vector)
eliminated %>% 
  filter(COMPANY %in% vector$vector) %>% 
  ggplot(aes(x=EARNINGS_Scaled, y= Earnings_next_year_Scaled, group = COMPANY))+
  geom_smooth(method = "lm", se= FALSE, size = 0.5)
```

We believe it makes sense to replace the global earnings coefficientwith a company specific earnings coefficient. 


```{r}
Diff_inter_slope_train <- readRDS("Diff_inter_slope_train_nick.rds")
```

```{r, eval=FALSE}
model_diff_inter_slope_train_data <- training %>%
  select(c("Earnings_next_year_Scaled","Sector","COMPANY","EARNINGS_Scaled","EARNINGS_1_YEAR_AGO")) %>% 
  na.omit()

diff_slope_inter_model_train <- stan_glmer(
  Earnings_next_year_Scaled ~ EARNINGS_Scaled + EARNINGS_1_YEAR_AGO + (EARNINGS_Scaled | COMPANY) + Sector, data = model_diff_inter_slope_train_data, 
  family = gaussian,
  chains = 4, iter = 5000*2, seed = 84735, 
  prior_PD = FALSE)
write_rds(diff_slope_inter_model_train, "Diff_inter_slope_train_nick.rds")
```

```{r, eval=FALSE}
prior_summary(Diff_inter_slope_train)
```

Different intercepts & slopes model notation: 

$$\begin{split}
Y_{ij} | \beta_{0j}, \beta_{1j}, \sigma_y & \sim N(\mu_{ij}, \sigma_y^2) \;\; \text{ where } \; \mu_{ij} = \beta_{0j} + \beta_{1j} X_{ij} + \beta_{2} X_{ij}  + \beta_{3} X_{ij}...\\
& \\
\beta_{0j} & \sim N(\beta_0, \sigma_0^2) \\
\beta_{1j} & \sim N(\beta_1, \sigma_1^2) \\
& \\
\beta_{0c} & \sim N(0.59, 1.5^2)  \\
\beta_1 & \sim N(0, 1.74^2) \\
.\\
.\\
.\\
\sigma_y & \sim \text{Exp}(1.6)    \\
\sigma_0, \sigma_1, ... & \sim \text{(something a bit complicated)}. \\
\end{split}$$


## Model Evaluations

### Is this the right model? 

Next we plot the posterior distributions and compare to the actual values observed in the data set. 

```{r}
pp_check(Diff_inter_train) 
pp_check(Diff_inter_slope_train)
```

Again, several company earnings' on the right seem to be causing model fitness difficulties. Both models run into this problem. 

There seems to be little difference between the two models in terms of fitting the structure of earnings next year. We will now dive into predicting the accuracy of the models. 


### How Accurate are the models? 


**Model 1 - Specific Examples with companies:**

Below, we compare our predictions for American Airlines. We plot 750 random values predicted from our predictions (out of 20,000). As we can see below our predictions range cover the actual value of earnings for 2020 fiscal year for both models. 

```{r}
set.seed(84732)
predict_model("AAL", Diff_inter_train)
# mcmc_areas(predict_next_year, prob = 0.8) +
#   ggplot2::scale_y_discrete(labels = c(`test_comp`)) + geom_vline(xintercept = actual, linetype = "dashed", colour = "red") 
#Need Help Because X scale is different
```


**Model 2 - Specific Examples with companies:**

```{r}
set.seed(84732)
predict_model("AAL", Diff_inter_slope_train)
# mcmc_areas(predict_next_year, prob = 0.8) +
#   ggplot2::scale_y_discrete(labels = c(`test_comp`)) + geom_vline(xintercept = actual, linetype = "dashed", colour = "red") 
```


The predictions for the second model seem to be slightly better as more posterior predictive points are near the actual value for "2020".


```{r, include=FALSE}
set.seed(84732)
testing_1 <- testing %>% 
  na.omit()
Diff_inter_metrics <- collect_metrics_pred(Diff_inter_train, testing_1)
```


```{r, include=FALSE}
set.seed(84732)
testing_1 <- testing %>%
  na.omit()
Diff_inter_slope_metrics <- collect_metrics_pred(Diff_inter_slope_train, testing_1)
```


**Evaluating Metrics**

Different Intercepts Model:

```{r}
Diff_inter_metrics
```

Different Intercepts & Slopes Model:

```{r}
Diff_inter_slope_metrics
```

We can see that our model with varying intercepts and slopes (model 2) preforms slightly better. Where our average median posterior prediction is off by 0.28 billion as opposed to 0.362 billion when we only have differing intercepts. Furthermore, our 95 and 50 interval values are both  better in the model with different intercept and slope.


**Shrinkage **

Since we modeled based off different companies having different intercepts, it is worthwhile to checkout how the company baselines shrunk compared to each other and between the two different models. 

Model 1 Shrinkage:

```{r, echo=FALSE}
set.seed(84732)
COMPANY_chains <- Diff_inter_train %>%
  spread_draws(`(Intercept)`, b[,COMPANY]) %>%
  mutate(mu_j = `(Intercept)` + b)
COMPANY_summary_scaled <- COMPANY_chains %>%
  select(-`(Intercept)`, -b) %>%
  mean_qi(.width = 0.80) %>%
  mutate(COMPANY = fct_reorder(COMPANY, mu_j))
ggplot(
    sample_n(COMPANY_summary_scaled,70),
    aes(x = COMPANY, y = mu_j, ymin = .lower, ymax = .upper)) +
    geom_pointrange() +
    geom_hline(yintercept = mean(data$Earnings_next_year_Scaled), linetype = "dashed") + 
  xaxis_text(angle = 90, hjust = 1)
```


Model 2 Shrinkage:

```{r, echo=FALSE}
set.seed(84732)
COMPANY_chains <- Diff_inter_slope_train %>%
  spread_draws(`(Intercept)`, b[,COMPANY]) %>%
  mutate(mu_j = `(Intercept)` + b)
COMPANY_summary_scaled <- COMPANY_chains %>%
  select(-`(Intercept)`, -b) %>%
  mean_qi(.width = 0.80) %>%
  mutate(COMPANY = fct_reorder(COMPANY, mu_j))
ggplot(
    sample_n(COMPANY_summary_scaled,70),
    aes(x = COMPANY, y = mu_j, ymin = .lower, ymax = .upper)) +
    geom_pointrange() +
    geom_hline(yintercept = mean(data$Earnings_next_year_Scaled), linetype = "dashed") + 
  xaxis_text(angle = 90, hjust = 1)
```



**Global Standard Deviation Parameters: NOT COMPLETED ADFASGARGERGEARG**

```{r, eval=FALSE}
tidy(model_2, effects = "ran_pars")
(0.4512^2)/((0.4512^2) + (0.5519447^2))

tidy(model_3, effects = "ran_pars")
(0.4294^2)/((0.4294^2) + (0.5450631)^2)
```

In model 2, about 40.06% of the variance can be explained between companies. In model 3, about 38.29% of the variance can be explained between companies. This means that when including sectors and lagged variables, more variable shrinkage occurred. Unfortunately this shrinkage is not as evident in the plotted graphs above. Model 3's baseline intercepts differ among each other slightly less than model 2's. 



# Bayes Forecast

```{r}
library(bayesforecast)
```

**Bayesian Forecast SARIMA:**

In our last model specification, we decided to use the bayesforecast package. In particular we are fitting a SARIMA model in Stan.

SARIMA stands for seasonal auto-regressive integrated moving average. This is an extension of ARIMA and is therefore more robust as it is able to support seasonal data. 

ARIMA is a method that combines both auto-regressive methods and moving averages- it is widely used on time series data in attempts to predict future values. There are four components that explain time series data, trend, seasonality, irregularity, and cyclic components. 


**Reason to use Bayesian forecast:**

The reason that we are using Bayesian forecast is that we could see the prediction of the earnings for not only the next year but for 10 years in the future. Bayesian forecast was created based on seasonal order, trend or seasonality, which could predict the model fairly accurately. 

After running the model, we then move on to predict the earnings of the future year for the companies. The companies we are going to predict will be Amazon (symbol: "AMZN"), American Airlines (symbol: "AAL"), and Koka Kola (symbol: "KO"). 


## Model Parameters

Here are the parameters for an ARIMA model: 

P - Order of the AR term. This is the number of Y to be used as predictors. For example, if we are predicting 2021 earnings, how many previous years earnings are we going to use? 

Q - Order of the MA term. This is the number of lagged forecast errors. How many past forecast errors will we be using? 

D - The minimum differencing period. A stationary time series implies one that has properties that do not depend on the time at which the series is observed. 


As mentioned above, SARIMA is able to support seasonal data. Below are the parameters for a SARIMA model that ARIMA does not have. 


P - Seasonal autoregressive order. A P=1 would make use of the first seasonally offset observation in the model, e.g. t-(m1) or t-12. A P=2, would use the last two seasonally offset observations t-(m1), t-(m2).

D - Seasonal difference order. A D of 1 would calculate a first order seasonal difference and a Q=1 would use a first order error in the model (e.g. moving average).

Q - Seasonal moving average order.

M - The number of time steps for a single seasonal period. M is a very important parameter as it influences the P, D, and Q parameters. For example, an m of 5 for yearly data suggests a 5-year seasonal cycle (in the context of business cycles. 


## Modeling

After creating the model, we will then move on to predict the earnings of the future year for the companies. The companies we are going to predict will be Amazon (symbol: "AMZN"), American Airlines (symbol: "AAL"), and Coca Cola (symbol: "KO"). 


**Amazon Prediction**

```{r, results='hide'}
AMZN <- data %>% 
  filter(COMPANY == 'AMZN') %>% 
  dplyr::select(EARNINGS_Scaled) %>% 
  arrange(EARNINGS_Scaled)

vector <- AMZN$EARNINGS_Scaled

myts <- ts(vector, start=c(1999), end=c(2021), frequency=1)

sf_AMZN = stan_sarima(ts = myts,order = c(1,1,1),seasonal = c(1,1,1),
                  prior_mu0 = student(mu = 0,sd = 1,df = 7))
```

```{r fig3}
autoplot(forecast(object = sf_AMZN, h = 12))
```

First, for Amazon, we see that the earnings are predicted to increase from 2021 to 2030, moving from 21 billion to around 38 billion in 2030. However, we can see that the prediction states that the earnings growth tends to slow down over time over the period. 


**American Airlines Prediction**

```{r, results='hide'}
AAL <- data %>% 
  filter(COMPANY == 'AAL') %>% 
  dplyr::select(EARNINGS_Scaled) %>% 
  arrange(EARNINGS_Scaled)

vector <- AAL$EARNINGS_Scaled

myts <- ts(vector, start=c(1999), end=c(2021), frequency=1)

sf_AAL = stan_sarima(ts = myts,order = c(1,1,1),seasonal = c(1,1,1),
                  prior_mu0 = student(mu = 0,sd = 1,df = 7))
```

```{r}
autoplot(forecast(object = sf_AAL, h = 12))
```

For American Airlines, we see a different story. As we can see from the graph, as airlines industry is an extremely cyclical field, the earnings fluctuate a lot. We could see that they fluctuate a lot during the previous years. With that in mind, the model predicts that American Airlines will not improve the much during the following years from 2021 to 2030 as predicting a cyclical company's earnings could be a really difficult story. It did not show the similar pattern as Amazon. 


**Coca Cola Prediction**

```{r, results='hide'}
KO <- data %>% 
  filter(COMPANY == 'KO') %>% 
  dplyr::select(EARNINGS_Scaled) %>% 
  arrange(EARNINGS_Scaled)

vector_KO <- KO$EARNINGS_Scaled

myts_KO <- ts(vector_KO, start=c(1999), end=c(2021), frequency=1)

sf_KO = stan_sarima(ts = myts_KO,order = c(1,1,1),seasonal = c(1,1,1),
                  prior_mu0 = student(mu = 0,sd = 1,df = 7))
```

```{r}
autoplot(forecast(object = sf_KO,h = 12))
```

For Coca Cola, it follows the same case as American Airlines. Even though the earnings increase over time, the model predicts that Ford's earning will stay relatively the same throughout the year from 2021 to 2030. It should be fairly clear as Coca Cola is a company that has developed for a really long period of time and can be considered to be a dividend company. With that in mind, it is fairly reasonable to see the earnings of the company to stay relatively the same after a period. 
